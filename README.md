# Computer Vision Project

This project involved facilitating knowledge transfer between Vector and its industry sponsors. Specifically, the objectives were following: 

1. Learn about recent advances in deep learning for computer vision
2. Apply methods to novel use cases in industry

Several use cases involving both images and videos are explored. These use-cases reflected current industry needs, participantsâ€™ interests and expertise, and opportunities to translate academic advances into real-world applications: 

**Image Use Cases**
1. Unsupervised defect detection in manufacturing using autoencoders
2. Building footprint extraction using semantic segmentation
3. Road Obstactle Detection using semantic segmentation

**Video Use Cases**
1. Semantic segmentation of videos from cholecystectomy procedures (gallbladder surgery)
2. Traffic incident detection of videos using augment

## Additional Tooling
In addition, the AI Engineering team has created a separate repository that works as a tool-kit the Computer Vision project at Vector Institute. It includes various datasets readily loadable from the shared cluster as well as useful image/video tools such as data augmentation and visualization utilities.You can find the repository at https://github.com/VectorInstitute/vector_cv_tools

## Usage 
Each folder corresponding to a use case includes instructions to run the experiments. It should be noted that this repository is no longer maintained and solely serves as an artifact of the project. 

## Citations
Please ensure you cite [Computer Vision: Applications in Manufacturing, Surgery, Traffic, Satellites, and Unlabelled Data Recognition Technical Report](https://vectorinstitute.ai/wp-content/uploads/2022/05/computer_vision_project_report_may252022.pdf) whenever you are citing this GitHub repository

## Acknowledgements 
Many thanks to our sponsor companies, researchers and Vector Institute staff for making this collaboration possible and providing academic support and computing infrastructure during all phases of this work. We would specifically like to thank the following individuals for their contributions. 

* Elham Ahmadi
* Andrew Alberts-Scherer
* Raghav Goyal
* John Jewell
* Shuja Khalid
* Matthew Kowal
* Andriy Levitskyy
* Jinbiao Ning
* Tristan Trim
* Kuldeep Panjwani
* Saeed Pouryazdian
* Sim Sachar
* Yilei Wu
* An Zhou
